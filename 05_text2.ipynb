{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis (part 2)\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- Preprocess text.\n",
    "- Extract features.\n",
    "- Build a couple types of classification models.\n",
    "- Examine the performance of those models.\n",
    "- Use topic modeling to find emergent topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jkiley/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob, Word\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text\n",
    "\n",
    "There are a number of common ways to preprocess text for use in machine learning and other text analysis models.\n",
    "While these things are often helpful, feel free to experiment with your own models and text corpora.\n",
    "\n",
    "\n",
    "Note that we will look at some of this functionality in TextBlob, though as we will see, we often use scikit-learn's tools for these tasks.\n",
    "However, textblob makes it easy to see how these tools work.\n",
    "\n",
    "- lower case\n",
    "- punctuation removed\n",
    "- POS tagging\n",
    "- lemmatization\n",
    "- n-grams\n",
    "- stop words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ultimately, we want to turn our text into a matrix that gives the algorithm information to categorize text. That is more difficult if we miss the same words due to case, punctuation, or common words that don't help predict. So, we can clean our text to potentially make our predictions better.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text_1 = ('Ultimately, we want to turn our text into a matrix that '\n",
    "                 'gives the algorithm information to categorize text. That '\n",
    "                 'is more difficult if we miss the same words due to case, '\n",
    "                 'punctuation, or common words that don\\'t help predict. '\n",
    "                 'So, we can clean our text to potentially make our '\n",
    "                 'predictions better.')\n",
    "example_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'ultimately': 1,\n",
       "             'we': 3,\n",
       "             'want': 1,\n",
       "             'to': 4,\n",
       "             'turn': 1,\n",
       "             'our': 3,\n",
       "             'text': 3,\n",
       "             'into': 1,\n",
       "             'a': 1,\n",
       "             'matrix': 1,\n",
       "             'that': 3,\n",
       "             'gives': 1,\n",
       "             'the': 2,\n",
       "             'algorithm': 1,\n",
       "             'information': 1,\n",
       "             'categorize': 1,\n",
       "             'is': 1,\n",
       "             'more': 1,\n",
       "             'difficult': 1,\n",
       "             'if': 1,\n",
       "             'miss': 1,\n",
       "             'same': 1,\n",
       "             'words': 2,\n",
       "             'due': 1,\n",
       "             'case': 1,\n",
       "             'punctuation': 1,\n",
       "             'or': 1,\n",
       "             'common': 1,\n",
       "             'do': 1,\n",
       "             \"n't\": 1,\n",
       "             'help': 1,\n",
       "             'predict': 1,\n",
       "             'so': 1,\n",
       "             'can': 1,\n",
       "             'clean': 1,\n",
       "             'potentially': 1,\n",
       "             'make': 1,\n",
       "             'predictions': 1,\n",
       "             'better': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_blob_1 = TextBlob(example_text_1)\n",
    "e_blob_1.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a few things about the dictionary above.\n",
    "\n",
    "1. This text has been **tokenized**, meaning that it has been split into tokens that have meaning (words in this case).\n",
    "1. textblob make the words lowercase before counting them. The word \"that\" appears in the original text both capitalized and lower case. This is perhaps the most common transformation of all, so it is not surprising that it does that for us automatically.\n",
    "1. The punctuation has been removed. That's not always something we will want, but it is quite helpful in most cases.\n",
    "1. The word \"don't\" was split into `'do'` and ``\"n't\"``. The tokenizer is smart enough to separate it so that the negation is captured separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times, we would like to consider parts of speech, and there are quite good models for finding this information for words.\n",
    "textblob has this functionality built in.\n",
    "For some tasks, it can be helpful to treat words used as different parts of speech as different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ultimately', 'RB'),\n",
       " ('we', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('turn', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('text', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('matrix', 'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use slicing to look at the first ten.\n",
    "e_blob_1.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we may want to reduce words to their base or **lemmatized** form in order to construct better counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We tell the lemmatize method the part of speech.\n",
    "Word('learning').lemmatize('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common transformation is using more than one word at a time to capture context.\n",
    "These multi-word groups are called **n-grams**.\n",
    "We do have to be careful here, as the dimensionality (and, thus, computational intensity) grows very quickly.\n",
    "\n",
    "**Note:** we would typically add the n-grams to the single words as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words alone:  39\n",
      "Length of n-grams of 2: 51\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of words alone:  {len(e_blob_1.word_counts)}')\n",
    "print(f'Length of n-grams of 2: {len(e_blob_1.ngrams(2))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['ultimately', 'we', 'want', 'to', 'turn', 'our', 'text', 'into', 'a', 'matrix', 'that', 'gives', 'the', 'algorithm', 'information', 'to', 'categorize', 'text', 'that', 'is', 'more', 'difficult', 'if', 'we', 'miss', 'the', 'same', 'words', 'due', 'to', 'case', 'punctuation', 'or', 'common', 'words', 'that', 'do', \"n't\", 'help', 'predict', 'so', 'we', 'can', 'clean', 'our', 'text', 'to', 'potentially', 'make', 'our', 'predictions', 'better'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_blob_1.words.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ultimately',\n",
       " 'want',\n",
       " 'turn',\n",
       " 'text',\n",
       " 'matrix',\n",
       " 'gives',\n",
       " 'algorithm',\n",
       " 'information',\n",
       " 'categorize',\n",
       " 'text',\n",
       " 'difficult',\n",
       " 'miss',\n",
       " 'words',\n",
       " 'due',\n",
       " 'case',\n",
       " 'punctuation',\n",
       " 'common',\n",
       " 'words',\n",
       " \"n't\",\n",
       " 'help',\n",
       " 'predict',\n",
       " 'clean',\n",
       " 'text',\n",
       " 'potentially',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'better']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_blob_1_stop = [w for w in e_blob_1.words.lower() \n",
    "                 if w not in stopwords.words('english')]\n",
    "e_blob_1_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "We're going to use a built-in dataset of `sklearn` as an example for expediency, though the patterns we will see are generally quite common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NEWS_CATS = ['comp.sys.mac.hardware',\n",
    "              'sci.electronics',\n",
    "              'rec.sport.baseball',\n",
    "              'rec.sport.hockey']\n",
    "news_train = fetch_20newsgroups(subset='train',\n",
    "                                remove=('headers', 'footers', 'quotes'),\n",
    "                                categories=_NEWS_CATS)\n",
    "news_test = fetch_20newsgroups(subset='test',\n",
    "                               remove=('headers', 'footers', 'quotes'),\n",
    "                               categories=_NEWS_CATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice description that comes with this dataset.\n",
    "# You can uncomment and run it yourself if you like.\n",
    "# print(news_test['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn`'s text utilities do a lot of feature extraction for us relatively easily.\n",
    "We will look at them in a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the defaults.\n",
    "test_cv = CountVectorizer()\n",
    "test_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a few things:\n",
    "\n",
    "1. By default, `lowercase=True`. As we discussed before, this is a transform that is nearly universal.\n",
    "1. It has a default of `ngram_range=(1, 1)`, but we can see that we can specify n-grams.\n",
    "1. It can filter stop words, but it is off be default. As the [documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#stop-words) notes, there are reasons to worry about stop words.\n",
    "1. If we want to override the built-in behavior, it allows us to pass in our own functions for the `preprocessor` and `tokenizer` arguments.\n",
    "1. Note that we do not have POS tagging built-in, but we could preprocess the text ourselves to feed in data with tags.\n",
    "\n",
    "Let's see some output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allows', 'and', 'arguments', 'behavior', 'built', 'but', 'could', 'data', 'do', 'feed', 'for', 'functions', 'have', 'if', 'in', 'it', 'not', 'note', 'our', 'ourselves', 'override', 'own', 'pass', 'pos', 'preprocess', 'preprocessor', 'tagging', 'tags', 'text', 'that', 'the', 'to', 'tokenizer', 'us', 'want', 'we', 'with']\n",
      "[[1 1 1 1 1 0 0 0 0 0 1 1 0 1 2 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 2 2 1 1 1 1\n",
      "  0]\n",
      " [0 0 0 0 1 1 1 1 1 1 0 0 1 0 2 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 2\n",
      "  1]]\n"
     ]
    }
   ],
   "source": [
    "test_sentences = ['If we want to override the built-in behavior, '\n",
    "                  'it allows us to pass in our own functions for the '\n",
    "                  ' preprocessor and tokenizer arguments.',\n",
    "                  'Note that we do not have POS tagging built-in, '\n",
    "                  'but we could preprocess the '\n",
    "                  'text ourselves to feed in data with tags.']\n",
    "test_sent_vec = test_cv.fit_transform(test_sentences)\n",
    "print(test_cv.get_feature_names())\n",
    "print(test_sent_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allows', 'allows us', 'and', 'and tokenizer', 'arguments', 'behavior', 'behavior it', 'built', 'built in', 'but', 'but we', 'could', 'could preprocess', 'data', 'data with', 'do', 'do not', 'feed', 'feed in', 'for', 'for the', 'functions', 'functions for', 'have', 'have pos', 'if', 'if we', 'in', 'in behavior', 'in but', 'in data', 'in our', 'it', 'it allows', 'not', 'not have', 'note', 'note that', 'our', 'our own', 'ourselves', 'ourselves to', 'override', 'override the', 'own', 'own functions', 'pass', 'pass in', 'pos', 'pos tagging', 'preprocess', 'preprocess the', 'preprocessor', 'preprocessor and', 'tagging', 'tagging built', 'tags', 'text', 'text ourselves', 'that', 'that we', 'the', 'the built', 'the preprocessor', 'the text', 'to', 'to feed', 'to override', 'to pass', 'tokenizer', 'tokenizer arguments', 'us', 'us to', 'want', 'want to', 'we', 'we could', 'we do', 'we want', 'with', 'with tags']\n",
      "[[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 2 1 0 0 1 1 1 0 0\n",
      "  0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 2 1 1 0 2 0 1 1 1 1 1\n",
      "  1 1 1 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 2 0 1 1 0 0 0 1 1\n",
      "  1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 2 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what happens with n-grams of 2.\n",
    "test_cv_2 = CountVectorizer(ngram_range=(1, 2))\n",
    "test_sent_vec_2 = test_cv_2.fit_transform(test_sentences)\n",
    "print(test_cv_2.get_feature_names())\n",
    "print(test_sent_vec_2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue that may seem obvious from our discussion of stop words earlier is that some words don't do a lot for us in terms of prediction.\n",
    "Another strategy for dealing with that issue is weighting terms such that those that are less frequent receive a higher weight and vice versa.\n",
    "We call this **term frequency times inverse document frequency** or tf-idf.\n",
    "\n",
    "Another issue you may have thought of is that we're using raw counts above.\n",
    "Longer documents will naturally have higher counts, so we can normalize those values if we choose (like the example below).\n",
    "It is not that important for our examples, but some models are sensitive to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, let's look at it.\n",
    "test_tt_1 = TfidfTransformer()\n",
    "test_tt_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, by default, it both normalizes and uses idf, but we can change those arguments if we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14809752 0.14809752 0.14809752 0.14809752 0.14809752 0.14809752\n",
      "  0.14809752 0.1053726  0.1053726  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14809752 0.14809752 0.14809752 0.14809752 0.\n",
      "  0.         0.14809752 0.14809752 0.2107452  0.14809752 0.\n",
      "  0.         0.14809752 0.14809752 0.14809752 0.         0.\n",
      "  0.         0.         0.14809752 0.14809752 0.         0.\n",
      "  0.14809752 0.14809752 0.14809752 0.14809752 0.14809752 0.14809752\n",
      "  0.         0.         0.         0.         0.14809752 0.14809752\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2107452  0.14809752 0.14809752 0.         0.2107452\n",
      "  0.         0.14809752 0.14809752 0.14809752 0.14809752 0.14809752\n",
      "  0.14809752 0.14809752 0.14809752 0.1053726  0.         0.\n",
      "  0.14809752 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10840958 0.10840958 0.15236588 0.15236588 0.15236588\n",
      "  0.15236588 0.15236588 0.15236588 0.15236588 0.15236588 0.15236588\n",
      "  0.15236588 0.         0.         0.         0.         0.15236588\n",
      "  0.15236588 0.         0.         0.21681916 0.         0.15236588\n",
      "  0.15236588 0.         0.         0.         0.15236588 0.15236588\n",
      "  0.15236588 0.15236588 0.         0.         0.15236588 0.15236588\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15236588 0.15236588 0.15236588 0.15236588 0.         0.\n",
      "  0.15236588 0.15236588 0.15236588 0.15236588 0.15236588 0.15236588\n",
      "  0.15236588 0.10840958 0.         0.         0.15236588 0.10840958\n",
      "  0.15236588 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.21681916 0.15236588 0.15236588\n",
      "  0.         0.15236588 0.15236588]]\n"
     ]
    }
   ],
   "source": [
    "test_sent_tdidf_1 = test_tt_1.fit_transform(test_sent_vec_2.toarray())\n",
    "print(test_sent_tdidf_1.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we looked at a number of the intermediate states, these tasks are common enough that the `TfidfVectorizer` class bundles together both `CountVectorizer` and `TfidfTransformer` into one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and performance: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline([('cv', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('model', MultinomialNB())\n",
    "                      ])\n",
    "\n",
    "pipeline_1.fit(news_train.data, news_train.target)\n",
    "news_pred = pipeline_1.predict(news_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a good start for evaluation.\n",
    "The values on the diagonal are correct classifications, and the off-diagonals are misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[339   3  16  27]\n",
      " [  4 339  48   6]\n",
      " [  1   8 386   4]\n",
      " [ 73   9  16 295]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(news_test.target, news_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.81      0.88      0.85       385\n",
      "   rec.sport.baseball       0.94      0.85      0.90       397\n",
      "     rec.sport.hockey       0.83      0.97      0.89       399\n",
      "      sci.electronics       0.89      0.75      0.81       393\n",
      "\n",
      "            micro avg       0.86      0.86      0.86      1574\n",
      "            macro avg       0.87      0.86      0.86      1574\n",
      "         weighted avg       0.87      0.86      0.86      1574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(news_test.target, news_pred,\n",
    "                            target_names=news_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and performance: Support Vector Machine\n",
    "\n",
    "SVM models are known for good performance on text, so let's see how it compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how similar this code is to the prior version.\n",
    "# We could have just changed the classifier.\n",
    "pipeline_2 = Pipeline([('cv', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('model', SGDClassifier(penalty='l2',\n",
    "                                             alpha=1e-3,\n",
    "                                             max_iter=5, tol=None))\n",
    "                      ])\n",
    "\n",
    "pipeline_2.fit(news_train.data, news_train.target)\n",
    "news_pred_2 = pipeline_2.predict(news_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[316  19   3  47]\n",
      " [  7 349  29  12]\n",
      " [  2  33 354  10]\n",
      " [ 46  23   2 322]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(news_test.target, news_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.85      0.82      0.84       385\n",
      "   rec.sport.baseball       0.82      0.88      0.85       397\n",
      "     rec.sport.hockey       0.91      0.89      0.90       399\n",
      "      sci.electronics       0.82      0.82      0.82       393\n",
      "\n",
      "            micro avg       0.85      0.85      0.85      1574\n",
      "            macro avg       0.85      0.85      0.85      1574\n",
      "         weighted avg       0.85      0.85      0.85      1574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(news_test.target, news_pred_2,\n",
    "                            target_names=news_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the performance is very slightly worse overall, but it is more consistent across labels.\n",
    "In general, like the NB, performance is good.\n",
    "This isn't unusual with categories that are fairly distinct (like many categories of firm press releases).\n",
    "\n",
    "However, let's try one more important part of fitting machine learning models: hyperparameter tuning.\n",
    "In this case, we are going to do a grid search with a couple of options to see if performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_params = {'cv__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "             'tfidf__use_idf': (True, False),\n",
    "             'model__alpha': (0.01, 0.001)}\n",
    "\n",
    "p2_grid = GridSearchCV(pipeline_2, p2_params, cv=3, n_jobs=-1)\n",
    "p2_grid.fit(news_train.data, news_train.target)\n",
    "\n",
    "news_pred_3 = p2_grid.predict(news_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[321  18   4  42]\n",
      " [  9 341  36  11]\n",
      " [  2  28 359  10]\n",
      " [ 49  22   4 318]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(news_test.target, news_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.84      0.83      0.84       385\n",
      "   rec.sport.baseball       0.83      0.86      0.85       397\n",
      "     rec.sport.hockey       0.89      0.90      0.90       399\n",
      "      sci.electronics       0.83      0.81      0.82       393\n",
      "\n",
      "            micro avg       0.85      0.85      0.85      1574\n",
      "            macro avg       0.85      0.85      0.85      1574\n",
      "         weighted avg       0.85      0.85      0.85      1574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(news_test.target, news_pred_3,\n",
    "                            target_names=news_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__ngram_range': (1, 1), 'model__alpha': 0.001, 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, the grid search results suggest that the words only model outperforms the ones using n-grams.\n",
    "That's not surprising for a model predicting clear categories like this, but n-grams are often helpful in cases where the categories are more nuanced.\n",
    "\n",
    "Looking at our confusion matrices, note that we see the model missing more on a couple pairs of groups: the hardware and electronics pair and the baseball and hockey pair.\n",
    "Given the overlap, that's logical.\n",
    "\n",
    "Our overall results here also illustrate another common pattern.\n",
    "Models like Naive Bayes give solid results with little hyperparameter tuning.\n",
    "As models increase in complexity, good performance often depends on more work on hyperparameters.\n",
    "I suggest starting with simpler models and working your way up as needed.\n",
    "\n",
    "For reporting results to reviewers, it's worth noting what you tried and the associated results.\n",
    "Many reviewers will not be familiar with machine learning, but chances are that editors will look for at least one, and he or she will likely want to see a bit of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
